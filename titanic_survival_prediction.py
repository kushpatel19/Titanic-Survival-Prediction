# -*- coding: utf-8 -*-
"""Titanic Survival Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LhRmutC0nc3XTckxf_p4KVQDYnDGrQga

Importing the Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, confusion_matrix

"""Data Collection & Processing"""

# load the data from csv file to Pandas DataFrame
titanic_data = pd.read_csv('https://github.com/kushpatel19/Titanic-Survival-Prediction/blob/main/Data.csv')

# printing the first 5 rows of the dataframe
titanic_data.head()

# number of rows and Columns
titanic_data.shape

# getting some informations about the data
titanic_data.info()

# check the number of missing values in each column
titanic_data.isnull().sum()

"""Handling the Missing values"""

# drop the "Cabin" column from the dataframe
titanic_data = titanic_data.drop(columns='Cabin', axis=1)

# replacing the missing values in "Age" column with mean value
titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)

# finding the mode value of "Embarked" column
print(titanic_data['Embarked'].mode())

print(titanic_data['Embarked'].mode()[0])

# replacing the missing values in "Embarked" column with mode value
titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)

# check the number of missing values in each column
titanic_data.isnull().sum()

"""Data Analysis"""

# getting some statistical measures about the data
titanic_data.describe()

# finding the number of people survived and not survived
titanic_data['Survived'].value_counts()

"""Data Visualization"""

sns.set()

# making a count plot for "Survived" column
sns.countplot('Survived', data=titanic_data)

titanic_data['Sex'].value_counts()

# making a count plot for "Sex" column
sns.countplot('Sex', data=titanic_data)

# number of survivors Gender wise
sns.countplot('Sex', hue='Survived', data=titanic_data)

# making a count plot for "Pclass" column
sns.countplot('Pclass', data=titanic_data)

sns.countplot('Pclass', hue='Survived', data=titanic_data)

"""Encoding the Categorical Columns"""

titanic_data['Sex'].value_counts()

titanic_data['Embarked'].value_counts()

# converting categorical Columns

titanic_data.replace({'Sex':{'male':0,'female':1}, 'Embarked':{'S':0,'C':1,'Q':2}}, inplace=True)

titanic_data.head()

"""Separating features & Target"""

X = titanic_data.drop(columns = ['PassengerId','Name','Ticket','Survived'],axis=1)
Y = titanic_data['Survived']
print(X)
print(Y)

"""Splitting the data into training data & Test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Model Training
Machine Learning Classification

Let's try all the clasification models                                        

- Support Vector Machine Model
- Logistic Regression
- AdaBoost Classifier 
- RandomForest Classifier
- GaussianNB
- K Nearest Neighbor(KNN)
- DecisionTree Classifier
- XGB Classifier 
- XGBRF Classifier
"""

from sklearn import svm
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from xgboost import XGBRFClassifier
from sklearn.ensemble import AdaBoostClassifier

def accuracy(model, title):
  model.fit(X_train, Y_train)
  predictions = model.predict(X_test)
  acc = accuracy_score(Y_test, predictions)
  print('Accuracy for', title, 'is :-', acc,'\n')

model_1 = svm.SVC(kernel='rbf')
accuracy(model_1,'Support Vector Machine Model')
model_2 = LogisticRegression()
accuracy(model_2,'Logistic Regression')
model_3 = AdaBoostClassifier()
accuracy(model_3,'Ada')
model_4 = RandomForestClassifier()
accuracy(model_4,'Random Forest')
model_5 = GaussianNB()
accuracy(model_5,'NBG')
model_6 = KNeighborsClassifier()
accuracy(model_6,'K Nearest Neighbor(KNN)')
model_7 = DecisionTreeClassifier()
accuracy(model_7,'Decision Tree')
model_8 = XGBClassifier()
accuracy(model_8,'XGB')
model_9 = XGBRFClassifier()
accuracy(model_9,'XGBRF')

"""Now, we will select the best model among them according to the highest score of accuracy

As we can see that, we will continue with  Random Forest Classifier.
"""

best_model = model_4

"""Model Evaluation

Accuracy Score
"""

# accuracy on training data
X_training_prediction = best_model.predict(X_train)

print(X_training_prediction)

training_data_accuracy = accuracy_score(Y_train, X_training_prediction)
print('Accuracy score of training data : ', training_data_accuracy)
print(classification_report(Y_train, X_training_prediction))

# # example of grid searching key hyperparametres for logistic regression
# from sklearn.datasets import make_blobs
# from sklearn.model_selection import RepeatedStratifiedKFold
# from sklearn.model_selection import GridSearchCV
# from sklearn.linear_model import LogisticRegression
# # define dataset
# # X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)
# # define models and parameters
# model = LogisticRegression()
# solvers = ['newton-cg', 'lbfgs', 'liblinear']
# penalty = ['l1','l2', 'elasticnet', 'none']
# c_values = [100, 10, 1.0, 0.1, 0.01]
# # define grid search
# grid = dict(solver=solvers,penalty=penalty,C=c_values)
# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
# grid_result = grid_search.fit(X_train, Y_train)
# # summarize results
# print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
# means = grid_result.cv_results_['mean_test_score']
# stds = grid_result.cv_results_['std_test_score']
# params = grid_result.cv_results_['params']
# for mean, stdev, param in zip(means, stds, params):
#     print("%f (%f) with: %r" % (mean, stdev, param))

"""Hyperperameter Tuning for increasing accuracy"""

best_model.get_params()

"""Important Parameters :-                                                     
- bootstrap
- Max_depth
- max_features
- min_samples_leaf
- min_samples_split
- n_estimators

1. GridSearchCV
"""

from sklearn.model_selection import GridSearchCV
 
# defining parameter range
param_grid =  {

'bootstrap': [True],

'max_depth': [80, 90, 100, 110],

'max_features': [2,3],

'min_samples_leaf': [3,4,5],

'min_samples_split': [8,10,12],

'n_estimators': [100, 200, 300, 1000]

}
grid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 10)
 
# fitting the model for grid search
grid.fit(X_train, Y_train)

# print best parameter after tuning
print(grid.best_params_)
 
# print how our model looks after hyper-parameter tuning
print(grid.best_estimator_)

grid_predictions = grid.predict(X_test)
 
# print classification report
print(classification_report(Y_test, grid_predictions))

"""2. RandomizedSearchCV"""

from scipy.stats import randint
from sklearn.model_selection import RandomizedSearchCV
 
# defining parameter range
param_grid =  {

'bootstrap': [True],

'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],

'max_features': ['auto', 'sqrt'],

'min_samples_leaf': [1, 2, 4],

'min_samples_split': [2, 5, 10],

'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]

}
              
random_search = RandomizedSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 10)
 
# fitting the model for random_search
random_search.fit(X_train, Y_train)
# print best parameter after tuning
print(random_search.best_params_)
 
# print how our model looks after hyper-parameter tuning
print(random_search.best_estimator_)


random_search_predictions = random_search.predict(X_test)
 
# print classification report
print(classification_report(Y_test, random_search_predictions))

